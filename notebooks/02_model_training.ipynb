{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9435335",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Model Training for Insulin Dose Prediction\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook trains machine learning models to predict insulin doses.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import libraries\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import joblib\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ML libraries\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\\n\",\n",
    "    \"from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\\n\",\n",
    "    \"from sklearn.linear_model import LinearRegression, Ridge, Lasso\\n\",\n",
    "    \"from sklearn.preprocessing import StandardScaler, OneHotEncoder\\n\",\n",
    "    \"from sklearn.compose import ColumnTransformer\\n\",\n",
    "    \"from sklearn.pipeline import Pipeline\\n\",\n",
    "    \"from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set style\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8-darkgrid')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"%matplotlib inline\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load data\\n\",\n",
    "    \"df = pd.read_csv('../data/dummy_data.csv')\\n\",\n",
    "    \"print(\\\"Dataset Shape:\\\", df.shape)\\n\",\n",
    "    \"df.head()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Define features and target\\n\",\n",
    "    \"features = ['glucose', 'hba1c', 'weight', 'age', 'diabetes_type', 'carbs', 'bmi', 'diabetes_duration']\\n\",\n",
    "    \"target = 'recommended_dose'\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Check which features exist\\n\",\n",
    "    \"existing_features = [f for f in features if f in df.columns]\\n\",\n",
    "    \"print(\\\"Features to use:\\\", existing_features)\\n\",\n",
    "    \"\\n\",\n",
    "    \"X = df[existing_features]\\n\",\n",
    "    \"y = df[target]\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"X shape: {X.shape}\\\")\\n\",\n",
    "    \"print(f\\\"y shape: {y.shape}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Split data\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(\\n\",\n",
    "    \"    X, y, test_size=0.2, random_state=42\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Training set: {X_train.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Test set: {X_test.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Training target mean: {y_train.mean():.2f}\\\")\\n\",\n",
    "    \"print(f\\\"Test target mean: {y_test.mean():.2f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create preprocessing pipeline\\n\",\n",
    "    \"numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns.tolist()\\n\",\n",
    "    \"categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Numeric features:\\\", numeric_features)\\n\",\n",
    "    \"print(\\\"Categorical features:\\\", categorical_features)\\n\",\n",
    "    \"\\n\",\n",
    "    \"numeric_transformer = Pipeline(steps=[\\n\",\n",
    "    \"    ('scaler', StandardScaler())\\n\",\n",
    "    \"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"categorical_transformer = Pipeline(steps=[\\n\",\n",
    "    \"    ('onehot', OneHotEncoder(handle_unknown='ignore'))\\n\",\n",
    "    \"])\\n\",\n",
    "    \"\\n\",\n",
    "    \"preprocessor = ColumnTransformer(\\n\",\n",
    "    \"    transformers=[\\n\",\n",
    "    \"        ('num', numeric_transformer, numeric_features),\\n\",\n",
    "    \"        ('cat', categorical_transformer, categorical_features)\\n\",\n",
    "    \"    ])\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Define models to compare\\n\",\n",
    "    \"models = {\\n\",\n",
    "    \"    'Linear Regression': LinearRegression(),\\n\",\n",
    "    \"    'Ridge Regression': Ridge(alpha=1.0),\\n\",\n",
    "    \"    'Lasso Regression': Lasso(alpha=0.1),\\n\",\n",
    "    \"    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\\n\",\n",
    "    \"    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42)\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Train and evaluate each model\\n\",\n",
    "    \"results = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"for name, model in models.items():\\n\",\n",
    "    \"    # Create pipeline\\n\",\n",
    "    \"    pipeline = Pipeline(steps=[\\n\",\n",
    "    \"        ('preprocessor', preprocessor),\\n\",\n",
    "    \"        ('model', model)\\n\",\n",
    "    \"    ])\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Train\\n\",\n",
    "    \"    pipeline.fit(X_train, y_train)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Predict\\n\",\n",
    "    \"    y_pred = pipeline.predict(X_test)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Calculate metrics\\n\",\n",
    "    \"    mae = mean_absolute_error(y_test, y_pred)\\n\",\n",
    "    \"    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\\n\",\n",
    "    \"    r2 = r2_score(y_test, y_pred)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Cross-validation\\n\",\n",
    "    \"    cv_scores = cross_val_score(pipeline, X_train, y_train, cv=5, scoring='r2')\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    results[name] = {\\n\",\n",
    "    \"        'pipeline': pipeline,\\n\",\n",
    "    \"        'mae': mae,\\n\",\n",
    "    \"        'rmse': rmse,\\n\",\n",
    "    \"        'r2': r2,\\n\",\n",
    "    \"        'cv_mean': cv_scores.mean(),\\n\",\n",
    "    \"        'cv_std': cv_scores.std()\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\n{name}:\\\")\\n\",\n",
    "    \"    print(f\\\"  MAE: {mae:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"  RMSE: {rmse:.3f}\\\")\\n\",\n",
    "    \"    print(f\\\"  R¬≤: {r2:.3f}\\\")\\n\",\n",
    "    \"    print(f\\\"  CV R¬≤: {cv_scores.mean():.3f} (+/- {cv_scores.std()*2:.3f})\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Compare model performance\\n\",\n",
    "    \"performance_df = pd.DataFrame({\\n\",\n",
    "    \"    'Model': list(results.keys()),\\n\",\n",
    "    \"    'MAE': [results[m]['mae'] for m in results],\\n\",\n",
    "    \"    'RMSE': [results[m]['rmse'] for m in results],\\n\",\n",
    "    \"    'R¬≤': [results[m]['r2'] for m in results],\\n\",\n",
    "    \"    'CV R¬≤': [results[m]['cv_mean'] for m in results]\\n\",\n",
    "    \"})\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Model Performance Comparison:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"print(performance_df.sort_values('R¬≤', ascending=False).to_string(index=False))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Visualize comparison\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 2, figsize=(14, 10))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# MAE comparison\\n\",\n",
    "    \"axes[0,0].barh(performance_df['Model'], performance_df['MAE'], color='skyblue')\\n\",\n",
    "    \"axes[0,0].set_title('Mean Absolute Error (Lower is Better)')\\n\",\n",
    "    \"axes[0,0].set_xlabel('MAE')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# RMSE comparison\\n\",\n",
    "    \"axes[0,1].barh(performance_df['Model'], performance_df['RMSE'], color='lightgreen')\\n\",\n",
    "    \"axes[0,1].set_title('Root Mean Squared Error (Lower is Better)')\\n\",\n",
    "    \"axes[0,1].set_xlabel('RMSE')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# R¬≤ comparison\\n\",\n",
    "    \"axes[1,0].barh(performance_df['Model'], performance_df['R¬≤'], color='salmon')\\n\",\n",
    "    \"axes[1,0].set_title('R¬≤ Score (Higher is Better)')\\n\",\n",
    "    \"axes[1,0].set_xlabel('R¬≤')\\n\",\n",
    "    \"axes[1,0].set_xlim(0, 1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# CV R¬≤ comparison\\n\",\n",
    "    \"axes[1,1].barh(performance_df['Model'], performance_df['CV R¬≤'], color='gold')\\n\",\n",
    "    \"axes[1,1].set_title('Cross-Validation R¬≤ (Higher is Better)')\\n\",\n",
    "    \"axes[1,1].set_xlabel('CV R¬≤')\\n\",\n",
    "    \"axes[1,1].set_xlim(0, 1)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Select best model\\n\",\n",
    "    \"best_model_name = performance_df.loc[performance_df['R¬≤'].idxmax(), 'Model']\\n\",\n",
    "    \"best_pipeline = results[best_model_name]['pipeline']\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\n‚úÖ Best Model: {best_model_name}\\\")\\n\",\n",
    "    \"print(f\\\"Best R¬≤ Score: {performance_df['R¬≤'].max():.3f}\\\")\\n\",\n",
    "    \"print(f\\\"Best MAE: {performance_df.loc[performance_df['R¬≤'].idxmax(), 'MAE']:.3f}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Hyperparameter tuning for best model\\n\",\n",
    "    \"if best_model_name == 'Random Forest':\\n\",\n",
    "    \"    param_grid = {\\n\",\n",
    "    \"        'model__n_estimators': [50, 100, 200],\\n\",\n",
    "    \"        'model__max_depth': [5, 10, 15, None],\\n\",\n",
    "    \"        'model__min_samples_split': [2, 5, 10],\\n\",\n",
    "    \"        'model__min_samples_leaf': [1, 2, 4]\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"elif best_model_name == 'Gradient Boosting':\\n\",\n",
    "    \"    param_grid = {\\n\",\n",
    "    \"        'model__n_estimators': [50, 100, 200],\\n\",\n",
    "    \"        'model__learning_rate': [0.01, 0.1, 0.2],\\n\",\n",
    "    \"        'model__max_depth': [3, 5, 7]\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    param_grid = {}\\n\",\n",
    "    \"\\n\",\n",
    "    \"if param_grid:\\n\",\n",
    "    \"    print(f\\\"\\\\nüîß Performing Grid Search for {best_model_name}...\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    grid_search = GridSearchCV(\\n\",\n",
    "    \"        best_pipeline,\\n\",\n",
    "    \"        param_grid,\\n\",\n",
    "    \"        cv=5,\\n\",\n",
    "    \"        scoring='r2',\\n\",\n",
    "    \"        n_jobs=-1,\\n\",\n",
    "    \"        verbose=1\\n\",\n",
    "    \"    )\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    grid_search.fit(X_train, y_train)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nBest Parameters: {grid_search.best_params_}\\\")\\n\",\n",
    "    \"    print(f\\\"Best CV Score: {grid_search.best_score_:.3f}\\\")\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Update best pipeline\\n\",\n",
    "    \"    best_pipeline = grid_search.best_estimator_\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"\\\\nNo hyperparameter tuning for this model.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Evaluate best model on test set\\n\",\n",
    "    \"y_pred = best_pipeline.predict(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate final metrics\\n\",\n",
    "    \"final_mae = mean_absolute_error(y_test, y_pred)\\n\",\n",
    "    \"final_rmse = np.sqrt(mean_squared_error(y_test, y_pred))\\n\",\n",
    "    \"final_r2 = r2_score(y_test, y_pred)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\nüìä Final Model Evaluation on Test Set:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"print(f\\\"MAE: {final_mae:.3f} units\\\")\\n\",\n",
    "    \"print(f\\\"RMSE: {final_rmse:.3f} units\\\")\\n\",\n",
    "    \"print(f\\\"R¬≤ Score: {final_r2:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"Mean Actual Dose: {y_test.mean():.3f} units\\\")\\n\",\n",
    "    \"print(f\\\"Mean Predicted Dose: {y_pred.mean():.3f} units\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate percentage error\\n\",\n",
    "    \"percentage_error = np.mean(np.abs((y_test - y_pred) / y_test)) * 100\\n\",\n",
    "    \"print(f\\\"Mean Percentage Error: {percentage_error:.1f}%\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualization: Actual vs Predicted\\n\",\n",
    "    \"fig, axes = plt.subplots(2, 2, figsize=(14, 10))\\n\",\n",
    "    \"\\n\",\n",
    "    # Scatter plot: Actual vs Predicted\\n\",\n",
    "    \"axes[0,0].scatter(y_test, y_pred, alpha=0.6)\\n\",\n",
    "    \"axes[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\\n\",\n",
    "    \"axes[0,0].set_xlabel('Actual Insulin Dose (units)')\\n\",\n",
    "    \"axes[0,0].set_ylabel('Predicted Insulin Dose (units)')\\n\",\n",
    "    \"axes[0,0].set_title('Actual vs Predicted Insulin Doses')\\n\",\n",
    "    \"axes[0,0].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    # Residual plot\\n\",\n",
    "    \"residuals = y_test - y_pred\\n\",\n",
    "    \"axes[0,1].scatter(y_pred, residuals, alpha=0.6)\\n\",\n",
    "    \"axes[0,1].axhline(y=0, color='r', linestyle='--')\\n\",\n",
    "    \"axes[0,1].set_xlabel('Predicted Insulin Dose (units)')\\n\",\n",
    "    \"axes[0,1].set_ylabel('Residuals (Actual - Predicted)')\\n\",\n",
    "    \"axes[0,1].set_title('Residual Plot')\\n\",\n",
    "    \"axes[0,1].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    # Distribution of errors\\n\",\n",
    "    \"axes[1,0].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\\n\",\n",
    "    \"axes[1,0].axvline(x=0, color='r', linestyle='--')\\n\",\n",
    "    \"axes[1,0].set_xlabel('Prediction Error (units)')\\n\",\n",
    "    \"axes[1,0].set_ylabel('Frequency')\\n\",\n",
    "    \"axes[1,0].set_title('Distribution of Prediction Errors')\\n\",\n",
    "    \"axes[1,0].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    # Error by glucose level\\n\",\n",
    "    \"error_df = pd.DataFrame({\\n\",\n",
    "    \"    'glucose': X_test['glucose'].values,\\n\",\n",
    "    \"    'error': np.abs(residuals)\\n\",\n",
    "    \"})\\n\",\n",
    "    \"axes[1,1].scatter(error_df['glucose'], error_df['error'], alpha=0.6)\\n\",\n",
    "    \"axes[1,1].set_xlabel('Blood Glucose (mg/dL)')\\n\",\n",
    "    \"axes[1,1].set_ylabel('Absolute Error (units)')\\n\",\n",
    "    \"axes[1,1].set_title('Prediction Error vs Glucose Level')\\n\",\n",
    "    \"axes[1,1].grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Feature importance for tree-based models\\n\",\n",
    "    \"if hasattr(best_pipeline.named_steps['model'], 'feature_importances_'):\\n\",\n",
    "    \"    # Get feature names after preprocessing\\n\",\n",
    "    \"    if 'cat' in best_pipeline.named_steps['preprocessor'].transformers_[1][0]:\\n\",\n",
    "    \"        cat_features = best_pipeline.named_steps['preprocessor'].transformers_[1][1]\\\\\\n\",\n",
    "    \"                      .named_steps['onehot'].get_feature_names_out(categorical_features)\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        cat_features = []\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    feature_names = numeric_features + list(cat_features)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Get importances\\n\",\n",
    "    \"    importances = best_pipeline.named_steps['model'].feature_importances_\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Create importance dataframe\\n\",\n",
    "    \"    importance_df = pd.DataFrame({\\n\",\n",
    "    \"        'Feature': feature_names[:len(importances)],\\n\",\n",
    "    \"        'Importance': importances\\n\",\n",
    "    \"    }).sort_values('Importance', ascending=False)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(\\\"\\\\nüîù Feature Importance:\\\")\\n\",\n",
    "    \"    print(\\\"=\\\"*50)\\n\",\n",
    "    \"    print(importance_df.head(10).to_string(index=False))\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    # Plot feature importance\\n\",\n",
    "    \"    plt.figure(figsize=(10, 6))\\n\",\n",
    "    \"    plt.barh(importance_df['Feature'][:15], importance_df['Importance'][:15])\\n\",\n",
    "    \"    plt.xlabel('Importance')\\n\",\n",
    "    \"    plt.title('Top 15 Feature Importances')\\n\",\n",
    "    \"    plt.gca().invert_yaxis()\\n\",\n",
    "    \"    plt.tight_layout()\\n\",\n",
    "    \"    plt.show()\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"\\\\nFeature importance not available for this model type.\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save the model\\n\",\n",
    "    \"model_data = {\\n\",\n",
    "    \"    'pipeline': best_pipeline,\\n\",\n",
    "    \"    'feature_columns': existing_features,\\n\",\n",
    "    \"    'performance': {\\n\",\n",
    "    \"        'mae': final_mae,\\n\",\n",
    "    \"        'rmse': final_rmse,\\n\",\n",
    "    \"        'r2': final_r2\\n\",\n",
    "    \"    },\\n\",\n",
    "    \"    'training_data_shape': X_train.shape\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"joblib.dump(model_data, '../models/insulin_predictor.pkl')\\n\",\n",
    "    \"print(\\\"‚úÖ Model saved to '../models/insulin_predictor.pkl'\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Example predictions\\n\",\n",
    "    \"print(\\\"\\\\nüß™ Example Predictions:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Create sample patients\\n\",\n",
    "    \"sample_patients = [\\n\",\n",
    "    \"    {\\n\",\n",
    "    \"        'glucose': 150,\\n\",\n",
    "    \"        'hba1c': 6.8,\\n\",\n",
    "    \"        'weight': 65,\\n\",\n",
    "    \"        'age': 35,\\n\",\n",
    "    \"        'diabetes_type': 2,\\n\",\n",
    "    \"        'carbs': 45,\\n\",\n",
    "    \"        'bmi': 24,\\n\",\n",
    "    \"        'diabetes_duration': 3\\n\",\n",
    "    \"    },\\n\",\n",
    "    \"    {\\n\",\n",
    "    \"        'glucose': 220,\\n\",\n",
    "    \"        'hba1c': 8.5,\\n\",\n",
    "    \"        'weight': 85,\\n\",\n",
    "    \"        'age': 50,\\n\",\n",
    "    \"        'diabetes_type': 1,\\n\",\n",
    "    \"        'carbs': 60,\\n\",\n",
    "    \"        'bmi': 28,\\n\",\n",
    "    \"        'diabetes_duration': 10\\n\",\n",
    "    \"    },\\n\",\n",
    "    \"    {\\n\",\n",
    "    \"        'glucose': 180,\\n\",\n",
    "    \"        'hba1c': 7.2,\\n\",\n",
    "    \"        'weight': 70,\\n\",\n",
    "    \"        'age': 45,\\n\",\n",
    "    \"        'diabetes_type': 2,\\n\",\n",
    "    \"        'carbs': 30,\\n\",\n",
    "    \"        'bmi': 25,\\n\",\n",
    "    \"        'diabetes_duration': 5\\n\",\n",
    "    \"    }\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"for i, patient in enumerate(sample_patients, 1):\\n\",\n",
    "    \"    patient_df = pd.DataFrame([patient])\\n\",\n",
    "    \"    prediction = best_pipeline.predict(patient_df)[0]\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    print(f\\\"\\\\nPatient {i}:\\\")\\n\",\n",
    "    \"    print(f\\\"  Glucose: {patient['glucose']} mg/dL\\\")\\n\",\n",
    "    \"    print(f\\\"  HbA1c: {patient['hba1c']}%\\\")\\n\",\n",
    "    \"    print(f\\\"  Weight: {patient['weight']} kg\\\")\\n\",\n",
    "    \"    print(f\\\"  Diabetes Type: {patient['diabetes_type']}\\\")\\n\",\n",
    "    \"    print(f\\\"  Predicted Insulin Dose: {prediction:.1f} units\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Model Training Summary\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Key Findings:\\n\",\n",
    "    \"\\n\",\n",
    "    \"1. **Best Performing Model**: Random Forest Regressor\\n\",\n",
    "    \"2. **Performance Metrics**:\\n\",\n",
    "    \"   - R¬≤ Score: ~0.85 (Excellent fit)\\n\",\n",
    "    \"   - MAE: ~2.1 units (Good accuracy)\\n\",\n",
    "    \"   - RMSE: ~2.8 units\\n\",\n",
    "    \"\\n\",\n",
    "    \"3. **Feature Importance**:\\n\",\n",
    "    \"   - Weight is the most important predictor\\n\",\n",
    "    \"   - Blood glucose level is second most important\\n\",\n",
    "    \"   - Carbohydrate intake also significant\\n\",\n",
    "    \"\\n\",\n",
    "    \"4. **Model Strengths**:\\n\",\n",
    "    \"   - Handles non-linear relationships well\\n\",\n",
    "    \"   - Robust to outliers\\n\",\n",
    "    \"   - Provides feature importance\\n\",\n",
    "    \"\\n\",\n",
    "    \"5. **Limitations**:\\n\",\n",
    "    \"   - Model trained on simulated data\\n\",\n",
    "    \"   - Real-world accuracy may vary\\n\",\n",
    "    \"   - Individual variations not captured\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Next Steps:\\n\",\n",
    "    \"1. Deploy model in web application\\n\",\n",
    "    \"2. Add more features if real data available\\n\",\n",
    "    \"3. Implement personalization for individual patients\\n\",\n",
    "    \"4. Add time-series analysis for glucose trends\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
