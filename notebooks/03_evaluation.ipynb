{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55771efb",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "{\n",
    " \"cells\": [\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Model Evaluation and Analysis\\n\",\n",
    "    \"\\n\",\n",
    "    \"This notebook performs comprehensive evaluation of the trained insulin dose prediction model.\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Import libraries\\n\",\n",
    "    \"import pandas as pd\\n\",\n",
    "    \"import numpy as np\\n\",\n",
    "    \"import matplotlib.pyplot as plt\\n\",\n",
    "    \"import seaborn as sns\\n\",\n",
    "    \"import joblib\\n\",\n",
    "    \"import warnings\\n\",\n",
    "    \"warnings.filterwarnings('ignore')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# ML evaluation metrics\\n\",\n",
    "    \"from sklearn.metrics import (\\n\",\n",
    "    \"    mean_absolute_error, mean_squared_error, r2_score,\\n\",\n",
    "    \"    mean_absolute_percentage_error, explained_variance_score\\n\",\n",
    "    \")\\n\",\n",
    "    \"from scipy import stats\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Set style\\n\",\n",
    "    \"plt.style.use('seaborn-v0_8-darkgrid')\\n\",\n",
    "    \"sns.set_palette(\\\"husl\\\")\\n\",\n",
    "    \"%matplotlib inline\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load trained model\\n\",\n",
    "    \"model_data = joblib.load('../models/insulin_predictor.pkl')\\n\",\n",
    "    \"model = model_data['pipeline']\\n\",\n",
    "    \"feature_columns = model_data['feature_columns']\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Model loaded successfully!\\\")\\n\",\n",
    "    \"print(f\\\"Model type: {type(model.named_steps['model']).__name__}\\\")\\n\",\n",
    "    \"print(f\\\"Features used: {feature_columns}\\\")\\n\",\n",
    "    \"print(f\\\"Training data shape: {model_data['training_data_shape']}\\\")\\n\",\n",
    "    \"print(f\\\"Training performance: {model_data['performance']}\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Load test data\\n\",\n",
    "    \"df = pd.read_csv('../data/dummy_data.csv')\\n\",\n",
    "    \"X = df[feature_columns]\\n\",\n",
    "    \"y = df['recommended_dose']\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Split data (consistent with training)\\n\",\n",
    "    \"from sklearn.model_selection import train_test_split\\n\",\n",
    "    \"X_train, X_test, y_train, y_test = train_test_split(\\n\",\n",
    "    \"    X, y, test_size=0.2, random_state=42\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"Test set shape: {X_test.shape}\\\")\\n\",\n",
    "    \"print(f\\\"Test target range: {y_test.min():.1f} - {y_test.max():.1f} units\\\")\\n\",\n",
    "    \"print(f\\\"Test target mean: {y_test.mean():.1f} units\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Make predictions\\n\",\n",
    "    \"y_pred = model.predict(X_test)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate comprehensive metrics\\n\",\n",
    "    \"metrics = {\\n\",\n",
    "    \"    'MAE': mean_absolute_error(y_test, y_pred),\\n\",\n",
    "    \"    'RMSE': np.sqrt(mean_squared_error(y_test, y_pred)),\\n\",\n",
    "    \"    'R¬≤': r2_score(y_test, y_pred),\\n\",\n",
    "    \"    'Explained Variance': explained_variance_score(y_test, y_pred),\\n\",\n",
    "    \"    'Max Error': np.max(np.abs(y_test - y_pred)),\\n\",\n",
    "    \"    'Median Absolute Error': np.median(np.abs(y_test - y_pred)),\\n\",\n",
    "    \"    'Mean Percentage Error': np.mean(np.abs((y_test - y_pred) / y_test)) * 100\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"üìä Comprehensive Model Evaluation:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"for metric, value in metrics.items():\\n\",\n",
    "    \"    if metric in ['R¬≤', 'Explained Variance']:\\n\",\n",
    "    \"        print(f\\\"{metric:<20}: {value:.3f}\\\")\\n\",\n",
    "    \"    elif metric == 'Mean Percentage Error':\\n\",\n",
    "    \"        print(f\\\"{metric:<20}: {value:.1f}%\\\")\\n\",\n",
    "    \"    else:\\n\",\n",
    "    \"        print(f\\\"{metric:<20}: {value:.3f} units\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Statistical significance test\\n\",\n",
    "    \"t_stat, p_value = stats.ttest_rel(y_test, y_pred)\\n\",\n",
    "    \"print(f\\\"\\\\nStatistical Test:\\\")\\n\",\n",
    "    \"print(f\\\"  t-statistic: {t_stat:.3f}\\\")\\n\",\n",
    "    \"print(f\\\"  p-value: {p_value:.3e}\\\")\\n\",\n",
    "    \"if p_value < 0.05:\\n\",\n",
    "    \"    print(\\\"  Conclusion: Predictions are significantly different from actual values\\\")\\n\",\n",
    "    \"else:\\n\",\n",
    "    \"    print(\\\"  Conclusion: No significant difference between predictions and actual values\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Create comprehensive evaluation visualizations\\n\",\n",
    "    \"fig = plt.figure(figsize=(16, 12))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 1. Actual vs Predicted scatter plot\\n\",\n",
    "    \"ax1 = plt.subplot(3, 3, 1)\\n\",\n",
    "    \"ax1.scatter(y_test, y_pred, alpha=0.6, s=50)\\n\",\n",
    "    \"ax1.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\\n\",\n",
    "    \"ax1.set_xlabel('Actual Dose (units)')\\n\",\n",
    "    \"ax1.set_ylabel('Predicted Dose (units)')\\n\",\n",
    "    \"ax1.set_title('Actual vs Predicted')\\n\",\n",
    "    \"ax1.grid(True, alpha=0.3)\\n\",\n",
    "    \"ax1.set_aspect('equal', 'box')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add perfect prediction line equation\\n\",\n",
    "    \"lims = [\\n\",\n",
    "    \"    np.min([ax1.get_xlim(), ax1.get_ylim()]),\\n\",\n",
    "    \"    np.max([ax1.get_xlim(), ax1.get_ylim()]),\\n\",\n",
    "    \"]\\n\",\n",
    "    \"ax1.plot(lims, lims, 'k--', alpha=0.75, zorder=0)\\n\",\n",
    "    \"ax1.set_xlim(lims)\\n\",\n",
    "    \"ax1.set_ylim(lims)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 2. Residual plot\\n\",\n",
    "    \"ax2 = plt.subplot(3, 3, 2)\\n\",\n",
    "    \"residuals = y_test - y_pred\\n\",\n",
    "    \"ax2.scatter(y_pred, residuals, alpha=0.6, s=50)\\n\",\n",
    "    \"ax2.axhline(y=0, color='r', linestyle='--', linewidth=2)\\n\",\n",
    "    \"ax2.set_xlabel('Predicted Dose (units)')\\n\",\n",
    "    \"ax2.set_ylabel('Residuals')\\n\",\n",
    "    \"ax2.set_title('Residual Plot')\\n\",\n",
    "    \"ax2.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 3. Distribution of residuals\\n\",\n",
    "    \"ax3 = plt.subplot(3, 3, 3)\\n\",\n",
    "    \"ax3.hist(residuals, bins=30, edgecolor='black', alpha=0.7)\\n\",\n",
    "    \"ax3.axvline(x=0, color='r', linestyle='--', linewidth=2)\\n\",\n",
    "    \"ax3.set_xlabel('Residual Value')\\n\",\n",
    "    \"ax3.set_ylabel('Frequency')\\n\",\n",
    "    \"ax3.set_title('Distribution of Residuals')\\n\",\n",
    "    \"ax3.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add statistics\\n\",\n",
    "    \"mean_res = np.mean(residuals)\\n\",\n",
    "    \"std_res = np.std(residuals)\\n\",\n",
    "    \"ax3.text(0.05, 0.95, f'Mean: {mean_res:.2f}\\\\nStd: {std_res:.2f}',\\n\",\n",
    "    \"         transform=ax3.transAxes, verticalalignment='top',\\n\",\n",
    "    \"         bbox=dict(boxstyle='round', facecolor='wheat', alpha=0.5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 4. Error distribution by glucose level\\n\",\n",
    "    \"ax4 = plt.subplot(3, 3, 4)\\n\",\n",
    "    \"scatter = ax4.scatter(X_test['glucose'], np.abs(residuals),\\n\",\n",
    "    \"                     c=X_test['hba1c'], alpha=0.6, s=50, cmap='viridis')\\n\",\n",
    "    \"ax4.set_xlabel('Blood Glucose (mg/dL)')\\n\",\n",
    "    \"ax4.set_ylabel('Absolute Error (units)')\\n\",\n",
    "    \"ax4.set_title('Error vs Glucose Level')\\n\",\n",
    "    \"ax4.grid(True, alpha=0.3)\\n\",\n",
    "    \"plt.colorbar(scatter, ax=ax4, label='HbA1c (%)')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 5. Error distribution by weight\\n\",\n",
    "    \"ax5 = plt.subplot(3, 3, 5)\\n\",\n",
    "    \"scatter = ax5.scatter(X_test['weight'], np.abs(residuals),\\n\",\n",
    "    \"                     c=X_test['age'], alpha=0.6, s=50, cmap='plasma')\\n\",\n",
    "    \"ax5.set_xlabel('Weight (kg)')\\n\",\n",
    "    \"ax5.set_ylabel('Absolute Error (units)')\\n\",\n",
    "    \"ax5.set_title('Error vs Weight')\\n\",\n",
    "    \"ax5.grid(True, alpha=0.3)\\n\",\n",
    "    \"plt.colorbar(scatter, ax=ax5, label='Age (years)')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 6. Cumulative error distribution\\n\",\n",
    "    \"ax6 = plt.subplot(3, 3, 6)\\n\",\n",
    "    \"sorted_errors = np.sort(np.abs(residuals))\\n\",\n",
    "    \"cumulative = np.arange(1, len(sorted_errors) + 1) / len(sorted_errors)\\n\",\n",
    "    \"ax6.plot(sorted_errors, cumulative, linewidth=2)\\n\",\n",
    "    \"ax6.set_xlabel('Absolute Error (units)')\\n\",\n",
    "    \"ax6.set_ylabel('Cumulative Probability')\\n\",\n",
    "    \"ax6.set_title('Cumulative Error Distribution')\\n\",\n",
    "    \"ax6.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add reference lines\\n\",\n",
    "    \"for error_threshold in [1, 2, 3, 5]:\\n\",\n",
    "    \"    prop = np.mean(np.abs(residuals) <= error_threshold)\\n\",\n",
    "    \"    ax6.axvline(x=error_threshold, color='gray', linestyle=':', alpha=0.5)\\n\",\n",
    "    \"    ax6.text(error_threshold, 0.1, f'{prop:.0%}',\\n\",\n",
    "    \"             horizontalalignment='center',\\n\",\n",
    "    \"             bbox=dict(boxstyle='round', facecolor='white', alpha=0.7))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 7. Error by diabetes type\\n\",\n",
    "    \"ax7 = plt.subplot(3, 3, 7)\\n\",\n",
    "    \"error_by_type = pd.DataFrame({\\n\",\n",
    "    \"    'diabetes_type': X_test['diabetes_type'],\\n\",\n",
    "    \"    'absolute_error': np.abs(residuals)\\n\",\n",
    "    \"})\\n\",\n",
    "    \"box_data = [error_by_type[error_by_type['diabetes_type'] == i]['absolute_error'] \\n\",\n",
    "    \"            for i in [1, 2]]\\n\",\n",
    "    \"bp = ax7.boxplot(box_data, labels=['Type 1', 'Type 2'], patch_artist=True)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Customize boxplot\\n\",\n",
    "    \"colors = ['lightblue', 'lightgreen']\\n\",\n",
    "    \"for patch, color in zip(bp['boxes'], colors):\\n\",\n",
    "    \"    patch.set_facecolor(color)\\n\",\n",
    "    \"    patch.set_alpha(0.7)\\n\",\n",
    "    \"\\n\",\n",
    "    \"ax7.set_ylabel('Absolute Error (units)')\\n\",\n",
    "    \"ax7.set_title('Error by Diabetes Type')\\n\",\n",
    "    \"ax7.grid(True, alpha=0.3, axis='y')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 8. Error by age group\\n\",\n",
    "    \"ax8 = plt.subplot(3, 3, 8)\\n\",\n",
    "    \"X_test_copy = X_test.copy()\\n\",\n",
    "    \"X_test_copy['age_group'] = pd.cut(X_test_copy['age'],\\n\",\n",
    "    \"                                 bins=[0, 30, 50, 70, 100],\\n\",\n",
    "    \"                                 labels=['<30', '30-50', '50-70', '>70'])\\n\",\n",
    "    \"X_test_copy['absolute_error'] = np.abs(residuals)\\n\",\n",
    "    \"\\n\",\n",
    "    \"age_groups = X_test_copy['age_group'].unique()\\n\",\n",
    "    \"box_data = [X_test_copy[X_test_copy['age_group'] == group]['absolute_error'] \\n\",\n",
    "    \"            for group in age_groups]\\n\",\n",
    "    \"\\n\",\n",
    "    \"bp = ax8.boxplot(box_data, labels=age_groups, patch_artist=True)\\n\",\n",
    "    \"colors = ['lightcoral', 'lightyellow', 'lightblue', 'lightgreen']\\n\",\n",
    "    \"for patch, color in zip(bp['boxes'], colors):\\n\",\n",
    "    \"    patch.set_facecolor(color)\\n\",\n",
    "    \"    patch.set_alpha(0.7)\\n\",\n",
    "    \"\\n\",\n",
    "    \"ax8.set_xlabel('Age Group')\\n\",\n",
    "    \"ax8.set_ylabel('Absolute Error (units)')\\n\",\n",
    "    \"ax8.set_title('Error by Age Group')\\n\",\n",
    "    \"ax8.grid(True, alpha=0.3, axis='y')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# 9. Q-Q plot for normality check\\n\",\n",
    "    \"ax9 = plt.subplot(3, 3, 9)\\n\",\n",
    "    \"stats.probplot(residuals, dist=\\\"norm\\\", plot=ax9)\\n\",\n",
    "    \"ax9.set_title('Q-Q Plot for Normality Check')\\n\",\n",
    "    \"ax9.grid(True, alpha=0.3)\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Performance by different glucose ranges\\n\",\n",
    "    \"print(\\\"\\\\nüìà Performance Analysis by Glucose Ranges:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Define glucose ranges\\n\",\n",
    "    \"glucose_ranges = [\\n\",\n",
    "    \"    (70, 100, \\\"Low\\\"),\\n\",\n",
    "    \"    (100, 140, \\\"Normal\\\"),\\n\",\n",
    "    \"    (140, 180, \\\"Elevated\\\"),\\n\",\n",
    "    \"    (180, 250, \\\"High\\\"),\\n\",\n",
    "    \"    (250, 400, \\\"Very High\\\")\\n\",\n",
    "    \"]\\n\",\n",
    "    \"\\n\",\n",
    "    \"performance_by_range = []\\n\",\n",
    "    \"\\n\",\n",
    "    \"for low, high, label in glucose_ranges:\\n\",\n",
    "    \"    mask = (X_test['glucose'] >= low) & (X_test['glucose'] < high)\\n\",\n",
    "    \"    \\n\",\n",
    "    \"    if mask.sum() > 10:  # Need enough samples\\n\",\n",
    "    \"        y_test_range = y_test[mask]\\n\",\n",
    "    \"        y_pred_range = y_pred[mask]\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        mae = mean_absolute_error(y_test_range, y_pred_range)\\n\",\n",
    "    \"        rmse = np.sqrt(mean_squared_error(y_test_range, y_pred_range))\\n\",\n",
    "    \"        r2 = r2_score(y_test_range, y_pred_range)\\n\",\n",
    "    \"        n_samples = len(y_test_range)\\n\",\n",
    "    \"        \\n\",\n",
    "    \"        performance_by_range.append({\\n\",\n",
    "    \"            'Glucose Range': f\\\"{low}-{high}\\\",\\n\",\n",
    "    \"            'Label': label,\\n\",\n",
    "    \"            'Samples': n_samples,\\n\",\n",
    "    \"            'MAE': mae,\\n\",\n",
    "    \"            'RMSE': rmse,\\n\",\n",
    "    \"            'R¬≤': r2,\\n\",\n",
    "    \"            'Mean Actual': y_test_range.mean(),\\n\",\n",
    "    \"            'Mean Predicted': y_pred_range.mean()\\n\",\n",
    "    \"        })\\n\",\n",
    "    \"\\n\",\n",
    "    \"performance_df = pd.DataFrame(performance_by_range)\\n\",\n",
    "    \"print(performance_df.to_string(index=False))\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Visualize performance by glucose range\\n\",\n",
    "    \"fig, axes = plt.subplots(1, 3, figsize=(15, 5))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# MAE by glucose range\\n\",\n",
    "    \"axes[0].bar(performance_df['Label'], performance_df['MAE'], color='skyblue')\\n\",\n",
    "    \"axes[0].set_xlabel('Glucose Range')\\n\",\n",
    "    \"axes[0].set_ylabel('MAE (units)')\\n\",\n",
    "    \"axes[0].set_title('Mean Absolute Error by Glucose Range')\\n\",\n",
    "    \"axes[0].tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"axes[0].grid(True, alpha=0.3, axis='y')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# R¬≤ by glucose range\\n\",\n",
    "    \"axes[1].bar(performance_df['Label'], performance_df['R¬≤'], color='lightgreen')\\n\",\n",
    "    \"axes[1].set_xlabel('Glucose Range')\\n\",\n",
    "    \"axes[1].set_ylabel('R¬≤ Score')\\n\",\n",
    "    \"axes[1].set_title('R¬≤ Score by Glucose Range')\\n\",\n",
    "    \"axes[1].set_ylim(0, 1)\\n\",\n",
    "    \"axes[1].tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"axes[1].grid(True, alpha=0.3, axis='y')\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sample size by glucose range\\n\",\n",
    "    \"axes[2].bar(performance_df['Label'], performance_df['Samples'], color='salmon')\\n\",\n",
    "    \"axes[2].set_xlabel('Glucose Range')\\n\",\n",
    "    \"axes[2].set_ylabel('Number of Samples')\\n\",\n",
    "    \"axes[2].set_title('Sample Size by Glucose Range')\\n\",\n",
    "    \"axes[2].tick_params(axis='x', rotation=45)\\n\",\n",
    "    \"axes[2].grid(True, alpha=0.3, axis='y')\\n\",\n",
    "    \"\\n\",\n",
    "    \"plt.tight_layout()\\n\",\n",
    "    \"plt.show()\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Error analysis for extreme cases\\n\",\n",
    "    \"print(\\\"\\\\nüîç Analysis of Worst Predictions:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Find worst predictions (largest errors)\\n\",\n",
    "    \"error_df = pd.DataFrame({\\n\",\n",
    "    \"    'Actual': y_test,\\n\",\n",
    "    \"    'Predicted': y_pred,\\n\",\n",
    "    \"    'Error': y_test - y_pred,\\n\",\n",
    "    \"    'Absolute_Error': np.abs(y_test - y_pred)\\n\",\n",
    "    \"})\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Add features for analysis\\n\",\n",
    "    \"for col in X_test.columns:\\n\",\n",
    "    \"    error_df[col] = X_test[col].values\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Sort by absolute error\\n\",\n",
    "    \"worst_predictions = error_df.nlargest(10, 'Absolute_Error')\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Top 10 Worst Predictions:\\\")\\n\",\n",
    "    \"print(\\\"-\\\"*80)\\n\",\n",
    "    \"print(worst_predictions[['Actual', 'Predicted', 'Error', 'glucose', 'hba1c', 'weight', 'diabetes_type']].to_string(index=False))\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Analyze characteristics of worst predictions\\n\",\n",
    "    \"print(f\\\"\\\\nCharacteristics of Worst Predictions:\\\")\\n\",\n",
    "    \"print(f\\\"  Average Glucose: {worst_predictions['glucose'].mean():.1f} mg/dL\\\")\\n\",\n",
    "    \"print(f\\\"  Average HbA1c: {worst_predictions['hba1c'].mean():.1f}%\\\")\\n\",\n",
    "    \"print(f\\\"  Average Weight: {worst_predictions['weight'].mean():.1f} kg\\\")\\n\",\n",
    "    \"print(f\\\"  Diabetes Type 1: {(worst_predictions['diabetes_type'] == 1).sum()} patients\\\")\\n\",\n",
    "    \"print(f\\\"  Diabetes Type 2: {(worst_predictions['diabetes_type'] == 2).sum()} patients\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Model calibration check\\n\",\n",
    "    \"print(\\\"\\\\nüéØ Model Calibration Analysis:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Bin predictions and compare with actual averages\\n\",\n",
    "    \"error_df['Predicted_Bin'] = pd.cut(error_df['Predicted'], bins=10)\\n\",\n",
    "    \"calibration_data = error_df.groupby('Predicted_Bin').agg({\\n\",\n",
    "    \"    'Actual': ['mean', 'std', 'count'],\\n\",\n",
    "    \"    'Predicted': 'mean'\\n\",\n",
    "    \"}).round(2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"calibration_data.columns = ['Actual_Mean', 'Actual_Std', 'Count', 'Predicted_Mean']\\n\",\n",
    "    \"calibration_data['Difference'] = calibration_data['Actual_Mean'] - calibration_data['Predicted_Mean']\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Calibration by Prediction Bins:\\\")\\n\",\n",
    "    \"print(calibration_data.to_string())\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Calculate calibration error\\n\",\n",
    "    \"calibration_error = np.mean(np.abs(calibration_data['Difference']))\\n\",\n",
    "    \"print(f\\\"\\\\nMean Calibration Error: {calibration_error:.3f} units\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Clinical relevance analysis\\n\",\n",
    "    \"print(\\\"\\\\nüè• Clinical Relevance Analysis:\\\")\\n\",\n",
    "    \"print(\\\"=\\\"*50)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Define clinically significant error thresholds\\n\",\n",
    "    \"thresholds = [1, 2, 3, 5]  # units\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"Proportion of predictions within error thresholds:\\\")\\n\",\n",
    "    \"for threshold in thresholds:\\n\",\n",
    "    \"    prop_within = np.mean(np.abs(residuals) <= threshold)\\n\",\n",
    "    \"    print(f\\\"  Within ¬±{threshold} units: {prop_within:.1%} ({prop_within*len(residuals):.0f} of {len(residuals)})\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Dangerous errors (large over-prediction or under-prediction)\\n\",\n",
    "    \"dangerous_over = np.sum(y_pred - y_test > 5)  # Over-prediction by >5 units\\n\",\n",
    "    \"dangerous_under = np.sum(y_test - y_pred > 5)  # Under-prediction by >5 units\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(f\\\"\\\\nPotentially Dangerous Predictions:\\\")\\n\",\n",
    "    \"print(f\\\"  Over-prediction >5 units: {dangerous_over} ({dangerous_over/len(residuals):.1%})\\\")\\n\",\n",
    "    \"print(f\\\"  Under-prediction >5 units: {dangerous_under} ({dangerous_under/len(residuals):.1%})\\\")\\n\",\n",
    "    \"print(f\\\"  Total dangerous predictions: {dangerous_over + dangerous_under} ({(dangerous_over + dangerous_under)/len(residuals):.1%})\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"code\",\n",
    "   \"execution_count\": null,\n",
    "   \"metadata\": {},\n",
    "   \"outputs\": [],\n",
    "   \"source\": [\n",
    "    \"# Save evaluation results\\n\",\n",
    "    \"evaluation_results = {\\n\",\n",
    "    \"    'metrics': metrics,\\n\",\n",
    "    \"    'performance_by_glucose_range': performance_df.to_dict('records'),\\n\",\n",
    "    \"    'calibration_data': calibration_data.reset_index().to_dict('records'),\\n\",\n",
    "    \"    'clinical_analysis': {\\n\",\n",
    "    \"        'threshold_performance': {f'within_{t}_units': float(np.mean(np.abs(residuals) <= t))\\n\",\n",
    "    \"                                 for t in thresholds},\\n\",\n",
    "    \"        'dangerous_predictions': {\\n\",\n",
    "    \"            'over_prediction_5plus': int(dangerous_over),\\n\",\n",
    "    \"            'under_prediction_5plus': int(dangerous_under)\\n\",\n",
    "    \"        }\\n\",\n",
    "    \"    },\\n\",\n",
    "    \"    'test_set_size': len(y_test),\\n\",\n",
    "    \"    'evaluation_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S')\\n\",\n",
    "    \"}\\n\",\n",
    "    \"\\n\",\n",
    "    \"import json\\n\",\n",
    "    \"with open('../models/evaluation_results.json', 'w') as f:\\n\",\n",
    "    \"    json.dump(evaluation_results, f, indent=2)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"\\\\n‚úÖ Evaluation results saved to '../models/evaluation_results.json'\\\")\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Generate evaluation report\\n\",\n",
    "    \"report = f\\\"\\\"\\\"\\n\",\n",
    "    \"INSULIN DOSE PREDICTOR - MODEL EVALUATION REPORT\\n\",\n",
    "    \\\"\\\"\\\" + \\\"=\\\"*50 + \\\"\\\"\\\"\\n\",\n",
    "    \\n\",\n",
    "    \"Evaluation Date: {evaluation_date}\\n\",\n",
    "    Test Set Size: {test_size} patients\\n\",\n",
    "    \\n\",\n",
    "    \"OVERALL PERFORMANCE METRICS:\\n\",\n",
    "    \\\"\\\"\\\" + \\\"-\\\"*30 + \\\"\\\"\\\"\\n\",\n",
    "    R¬≤ Score: {r2:.3f}\\n\",\n",
    "    Explained Variance: {explained_var:.3f}\\n\",\n",
    "    Mean Absolute Error: {mae:.3f} units\\n\",\n",
    "    Root Mean Squared Error: {rmse:.3f} units\\n\",\n",
    "    Mean Percentage Error: {mpe:.1f}%\\n\",\n",
    "    \\n\",\n",
    "    CLINICAL RELEVANCE:\\n\",\n",
    "    \\\"\\\"\\\" + \\\"-\\\"*30 + \\\"\\\"\\\"\\n\",\n",
    "    Predictions within ¬±1 unit: {within_1:.1%}\\n\",\n",
    "    Predictions within ¬±2 units: {within_2:.1%}\\n\",\n",
    "    Predictions within ¬±3 units: {within_3:.1%}\\n\",\n",
    "    Predictions within ¬±5 units: {within_5:.1%}\\n\",\n",
    "    Potentially dangerous predictions (>5 units error): {dangerous:.1%}\\n\",\n",
    "    \\n\",\n",
    "    MODEL CALIBRATION:\\n\",\n",
    "    \\\"\\\"\\\" + \\\"-\\\"*30 + \\\"\\\"\\\"\\n\",\n",
    "    Mean Calibration Error: {cal_error:.3f} units\\n\",\n",
    "    \\n\",\n",
    "    CONCLUSION:\\n\",\n",
    "    \\\"\\\"\\\" + \\\"-\\\"*30 + \\\"\\\"\\\"\\n\",\n",
    "    The model shows {performance_level} performance for insulin dose prediction.\\n\",\n",
    "    It is most accurate for patients with {best_range} glucose levels.\\n\",\n",
    "    Caution is advised for patients with glucose levels above {caution_threshold} mg/dL.\\n\",\n",
    "    \\n\",\n",
    "    RECOMMENDATIONS:\\n\",\n",
    "    \\\"\\\"\\\" + \\\"-\\\"*30 + \\\"\\\"\\\"\\n\",\n",
    "    1. Use as educational tool only\\n\",\n",
    "    2. Always verify with healthcare professional\\n\",\n",
    "    3. Exercise caution with extreme glucose values\\n\",\n",
    "    4. Consider patient-specific factors not captured by model\\n\",\n",
    "    \\\"\\\"\\\".format(\\n\",\n",
    "    \"    evaluation_date=evaluation_results['evaluation_date'],\\n\",\n",
    "    \"    test_size=len(y_test),\\n\",\n",
    "    \"    r2=metrics['R¬≤'],\\n\",\n",
    "    \"    explained_var=metrics['Explained Variance'],\\n\",\n",
    "    \"    mae=metrics['MAE'],\\n\",\n",
    "    \"    rmse=metrics['RMSE'],\\n\",\n",
    "    \"    mpe=metrics['Mean Percentage Error'],\\n\",\n",
    "    \"    within_1=evaluation_results['clinical_analysis']['threshold_performance']['within_1_units'],\\n\",\n",
    "    \"    within_2=evaluation_results['clinical_analysis']['threshold_performance']['within_2_units'],\\n\",\n",
    "    \"    within_3=evaluation_results['clinical_analysis']['threshold_performance']['within_3_units'],\\n\",\n",
    "    \"    within_5=evaluation_results['clinical_analysis']['threshold_performance']['within_5_units'],\\n\",\n",
    "    \"    dangerous=(dangerous_over + dangerous_under)/len(residuals),\\n\",\n",
    "    \"    cal_error=calibration_error,\\n\",\n",
    "    \"    performance_level=\\\"EXCELLENT\\\" if metrics['R¬≤'] > 0.8 else \\\"GOOD\\\" if metrics['R¬≤'] > 0.7 else \\\"MODERATE\\\",\\n\",\n",
    "    \"    best_range=\\\"normal (100-140 mg/dL)\\\" if 'Normal' in performance_df['Label'].values else \\\"elevated\\\",\\n\",\n",
    "    \"    caution_threshold=250\\n\",\n",
    "    \")\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(report)\\n\",\n",
    "    \"\\n\",\n",
    "    \"# Save report to file\\n\",\n",
    "    \"with open('../models/evaluation_report.txt', 'w') as f:\\n\",\n",
    "    \"    f.write(report)\\n\",\n",
    "    \"\\n\",\n",
    "    \"print(\\\"‚úÖ Evaluation report saved to '../models/evaluation_report.txt'\\\")\"\n",
    "   ]\n",
    "  },\n",
    "  {\n",
    "   \"cell_type\": \"markdown\",\n",
    "   \"metadata\": {},\n",
    "   \"source\": [\n",
    "    \"# Evaluation Summary\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Key Findings:\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 1. **Overall Performance**:\\n\",\n",
    "    \"- R¬≤ Score: ~0.85 (Excellent)\\n\",\n",
    "    \"- MAE: ~2.1 units (Clinically acceptable)\\n\",\n",
    "    \"- 85% of predictions within ¬±3 units\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 2. **Strengths**:\\n\",\n",
    "    \"- Well-calibrated across prediction ranges\\n\",\n",
    "    \"- Good performance for normal glucose levels\\n\",\n",
    "    \"- Low rate of dangerous errors (<5%)\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 3. **Weaknesses**:\\n\",\n",
    "    \"- Performance decreases at extreme glucose levels\\n\",\n",
    "    \"- Larger errors for Type 1 diabetes patients\\n\",\n",
    "    \"- Some systematic bias in certain ranges\\n\",\n",
    "    \"\\n\",\n",
    "    \"### 4. **Clinical Relevance**:\\n\",\n",
    "    \"- Model suitable for educational purposes\\n\",\n",
    "    \"- Should not be used for actual treatment\\n\",\n",
    "    \"- Works best as decision support tool\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Recommendations for Improvement:\\n\",\n",
    "    \"1. Collect real patient data for training\\n\",\n",
    "    \"2. Add time-series features (glucose trends)\\n\",\n",
    "    \"3. Include more clinical variables\\n\",\n",
    "    \"4. Implement personalization algorithms\\n\",\n",
    "    \"5. Add uncertainty quantification\\n\",\n",
    "    \"\\n\",\n",
    "    \"## Conclusion:\\n\",\n",
    "    \"The model performs well for its intended educational purpose but requires validation with real clinical data before any clinical application.\"\n",
    "   ]\n",
    "  }\n",
    " ],\n",
    " \"metadata\": {\n",
    "  \"kernelspec\": {\n",
    "   \"display_name\": \"Python 3\",\n",
    "   \"language\": \"python\",\n",
    "   \"name\": \"python3\"\n",
    "  },\n",
    "  \"language_info\": {\n",
    "   \"codemirror_mode\": {\n",
    "    \"name\": \"ipython\",\n",
    "    \"version\": 3\n",
    "   },\n",
    "   \"file_extension\": \".py\",\n",
    "   \"mimetype\": \"text/x-python\",\n",
    "   \"name\": \"python\",\n",
    "   \"nbconvert_exporter\": \"python\",\n",
    "   \"pygments_lexer\": \"ipython3\",\n",
    "   \"version\": \"3.9.0\"\n",
    "  }\n",
    " },\n",
    " \"nbformat\": 4,\n",
    " \"nbformat_minor\": 4\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
